{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579e425b-e5de-4fdc-9908-ed8706d57194",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example 01 - Train Online Sig53\n",
    "This notebook steps through an example of how to use `torchsig` to instantiate a `SignalDataset` containing 53 unique modulations. The notebook then plots the signals using `Visualizers` for both the IQ and Spectrogram representations of the dataset. The end of the notebook then shows how the instantiated dataset can be saved to an LMDB static dataset for standalone research, experimentation, and/or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d636a9e-55c1-47a1-bc20-9c472acecc3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "### Import Libraries\n",
    "First, import all the necessary public libraries as well as a few classes from the `torchsig` toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd181f0-893f-4646-8d7a-2fe2ee2280f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.models.iq_models.efficientnet.efficientnet import efficientnet_b4\n",
    "from torchsig.datasets.modulations import ModulationsDataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsig.datasets import conf\n",
    "from functools import partial\n",
    "import torchsig.transforms as ST\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d511e6b-7670-473b-a962-c08a9d341ec8",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "### Instantiate Modulations Dataset\n",
    "Next, instantiate the `ModulationsDataset` by passing in the desired classes, a boolean specifying whether to use the class name or index as the label, the desired level of signal impairments/augmentations, the number of IQ samples per example, and the total number of samples. Note that the total number of samples will be divided evenly among the class list (for example, `num_samples=5300` will result in 100x samples of each of the 53 modulation classes). Also note that the classes input parameter can be omitted if all classes are desired. \n",
    "\n",
    "If all classes are included at `level=0` (clean signals), all signals will occupy roughly half of the returned signal bandwidth except for the FSK and MSK modulations. These two subfamilies do not contain any pulse shaping, and as such are returned at roughly 1/8th occupied bandwidth for the main lobe. At the higher impairment levels, there is a randomized low pass filter applied at the 8x oversampled rate to suppress the sidelobes prior to downsampling to roughly the same half bandwidth target as the remaining signals.\n",
    "\n",
    "Within the OFDM family, there are 12 subclasses pertaining to the number of subcarriers present within the OFDM signal. These subcarriers are the powers of 2 from 64 to 2048 as well as the LTE specifications values of 72, 180, 300, 600, 900, and 1200. The DC subcarrier is randomly on or off throughout all subcarrier counts. The subcarrier modulations are divided into two categories: \n",
    "\n",
    "1. randomly select a single modulation from the list: `bpsk`, `qpsk`, `16qam`, `64qam`, `256qam`, and `1024qam` and modulate all subcarriers with the random selection; and \n",
    "\n",
    "2. randomly select a modulation from the same list for each subcarrier independently. \n",
    "\n",
    "The subcarrier modulations are not included in any of the labels for future classification tasks. In addition to these randomizations, the cyclic prefix ratio is also randomly selected between discrete values of 1/8 and 1/4, and it is also not included in the labels at this time. As a final randomization with the OFDM signals, two distinct sidelobe suppression techniques are evenly sampled from to smooth the discontinuities at the symbol boundaries: 1) apply a window, and 2) apply a low pass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e132f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ST.Compose([\n",
    "    ST.RandomPhaseShift(phase_offset=(-1, 1)),\n",
    "    ST.Normalize(norm=np.inf),\n",
    "    ST.ComplexTo2D(),\n",
    "])\n",
    "target_transform = ST.DescToClassIndex(class_list=ModulationsDataset.default_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afcf1b",
   "metadata": {},
   "source": [
    "## Choose a Configuration\n",
    "These are configurations used to generate the static Sig53 dataset.\n",
    "\n",
    "You can use them, or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a005753",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = conf.Sig53CleanTrainQAConfig\n",
    "# config = conf.Sig53CleanTrainConfig\n",
    "val_config = conf.Sig53CleanValQAConfig\n",
    "# config = conf.Sig53CleanValConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eacd833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234567891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 106\n",
      "Number of classes: 53\n",
      "Data shape: (2, 4096)\n",
      "Example modulation: 44\n"
     ]
    }
   ],
   "source": [
    "# Seed the dataset instantiation for reproduceability\n",
    "pl.seed_everything(1234567891)\n",
    "\n",
    "train_dataset = ModulationsDataset(\n",
    "    classes=ModulationsDataset.default_classes,\n",
    "    use_class_idx=train_config.use_class_idx,\n",
    "    level=train_config.level,\n",
    "    num_iq_samples=train_config.num_iq_samples,\n",
    "    num_samples=train_config.num_samples,\n",
    "    eb_no=train_config.eb_no,\n",
    "    include_snr=False,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "val_dataset = ModulationsDataset(\n",
    "    classes=ModulationsDataset.default_classes,\n",
    "    use_class_idx=val_config.use_class_idx,\n",
    "    level=val_config.level,\n",
    "    num_iq_samples=val_config.num_iq_samples,\n",
    "    num_samples=val_config.num_samples,\n",
    "    eb_no=val_config.eb_no,\n",
    "    include_snr=False,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "idx = np.random.randint(len(train_dataset))\n",
    "data, modulation = train_dataset[idx]\n",
    "\n",
    "\n",
    "print(\"Dataset length: {}\".format(len(train_dataset)))\n",
    "print(\"Number of classes: {}\".format(len(ModulationsDataset.default_classes)))\n",
    "print(\"Data shape: {}\".format(data.shape))\n",
    "print(\"Example modulation: {}\".format(modulation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1a32b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2818bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id: int, seed: int):\n",
    "    seed = seed + worker_id\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af232f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    worker_init_fn=partial(worker_init_fn, seed=train_config.seed),\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    worker_init_fn=partial(worker_init_fn, seed=val_config.seed),\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418f684",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e33e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_b4(\n",
    "    pretrained=True,\n",
    "    path=\"efficientnet_b4.pt\",\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfd583",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc97335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(pl.LightningModule):\n",
    "    def __init__(self, model, data_loader, val_data_loader):\n",
    "        super(ExampleModel, self).__init__()\n",
    "        self.mdl: torch.nn.Module = model\n",
    "        self.data_loader: DataLoader = data_loader\n",
    "        self.val_data_loader: DataLoader = val_data_loader\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.lr = 0.001\n",
    "        self.batch_size = data_loader.batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mdl(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.data_loader\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        loss = torch.nn.functional.cross_entropy(self(x.float()), y)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_data_loader\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y = torch.squeeze(y.to(torch.int64))\n",
    "        val_loss = torch.nn.functional.cross_entropy(self(x.float()), y)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        return {\"val_loss\": val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40bad9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model = ExampleModel(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64baf304",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0191395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type         | Params\n",
      "--------------------------------------\n",
      "0 | mdl  | EfficientNet | 17.3 M\n",
      "--------------------------------------\n",
      "17.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 M    Total params\n",
      "69.085    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvanhoy/Documents/projects/oscar/code/interference_detection/.venv/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6/6 [00:01<00:00,  3.27it/s, v_num=11, val_loss=2.290]"
     ]
    }
   ],
   "source": [
    "# Setup checkpoint callbacks\n",
    "checkpoint_filename = \"{}/checkpoints/checkpoint\".format(os.getcwd())\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=checkpoint_filename,\n",
    "    save_top_k=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# Create and fit trainer\n",
    "epochs = 25\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs, callbacks=checkpoint_callback, accelerator=\"gpu\", devices=[0]\n",
    ")\n",
    "trainer.fit(example_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b916f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0cc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "checkpoint = torch.load(checkpoint_filename+\".ckpt\", map_location=lambda storage, loc: storage)\n",
    "example_model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "example_model = example_model.eval()\n",
    "example_model = example_model.cuda() if torch.cuda.is_available() else example_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
